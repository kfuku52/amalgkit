#! /usr/bin/env python

import argparse
import os
import re
import shutil
import sys
import time

SCRIPT_DIR = os.path.realpath(os.path.dirname(__file__))
SCRIPT_PARENT_DIR = os.path.realpath(os.path.dirname(SCRIPT_DIR))

def sanitize_sys_path():
    cleaned = []
    for path_entry in sys.path:
        real_entry = os.path.realpath(path_entry if path_entry != '' else os.getcwd())
        if real_entry == SCRIPT_DIR:
            continue
        cleaned.append(path_entry)
    sys.path[:] = cleaned
    if SCRIPT_PARENT_DIR not in [os.path.realpath(p if p != '' else os.getcwd()) for p in sys.path]:
        sys.path.insert(0, SCRIPT_PARENT_DIR)

sanitize_sys_path()

from amalgkit.__init__ import __version__

DEPENDENCY_SPECS = [
    ('numpy', 'numpy'),
    ('pandas', 'pandas'),
    ('biopython', 'Bio'),
    ('ete4', 'ete4'),
]

EXTERNAL_TOOL_SPECS = [
    ('cat', 'cat', [['--version']]),
    ('seqkit', 'seqkit', [['version'], ['--help']]),
    ('R', 'R', [['--version']]),
    ('Rscript', 'Rscript', [['--version']]),
    ('kallisto', 'kallisto', [['version'], ['-h']]),
    ('fasterq-dump', 'fasterq-dump', [['--version'], ['-h']]),
    ('fastp', 'fastp', [['--version'], ['-h']]),
    ('busco', 'busco', [['--version'], ['-h']]),
    ('compleasm', 'compleasm', [['--version'], ['-h']]),
]

R_PACKAGE_SPECS = ['ggplot2', 'edgeR', 'Rtsne', 'RUVSeq', 'sva']

def resolve_dependency_version(package_name, module_name):
    _ = module_name  # keep signature stable for call sites
    normalized_target = re.sub(r'[-_.]+', '-', package_name).lower()
    for base_path in sys.path:
        if base_path == '':
            base_path = os.getcwd()
        if (not base_path) or (not os.path.isdir(base_path)):
            continue
        try:
            entries = os.listdir(base_path)
        except OSError:
            continue
        for entry in entries:
            if not entry.endswith('.dist-info'):
                continue
            metadata_path = os.path.join(base_path, entry, 'METADATA')
            if not os.path.isfile(metadata_path):
                continue
            dist_name = None
            dist_version = None
            try:
                with open(metadata_path, 'rt', encoding='utf-8', errors='replace') as handle:
                    for line in handle:
                        if (dist_name is None) and line.startswith('Name: '):
                            dist_name = line[len('Name: '):].strip()
                        elif (dist_version is None) and line.startswith('Version: '):
                            dist_version = line[len('Version: '):].strip()
                        if (dist_name is not None) and (dist_version is not None):
                            break
            except OSError:
                continue
            if dist_name is None:
                continue
            normalized_name = re.sub(r'[-_.]+', '-', dist_name).lower()
            if normalized_name == normalized_target:
                if dist_version:
                    return dist_version
                return 'UNKNOWN (distribution metadata missing Version)'
    return 'MISSING'

def describe_os():
    if hasattr(os, 'uname'):
        uname = os.uname()
        return '{} {} {} {}'.format(uname.sysname, uname.release, uname.version, uname.machine)
    return sys.platform

def first_nonempty_line(text):
    if text is None:
        return ''
    for line in text.splitlines():
        line = line.strip()
        if line != '':
            return line
    return ''

def run_command_capture(command):
    import subprocess
    try:
        out = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=5,
        )
        return out.returncode, out.stdout, out.stderr, None
    except Exception as exc:
        return None, '', '', exc

def resolve_external_tool_status(executable_name, version_commands):
    tool_path = shutil.which(executable_name)
    if tool_path is None:
        return 'MISSING'
    for version_args in version_commands:
        returncode, stdout_txt, stderr_txt, exc = run_command_capture([tool_path] + version_args)
        if exc is not None:
            continue
        candidate = first_nonempty_line(stdout_txt)
        if candidate == '':
            candidate = first_nonempty_line(stderr_txt)
        if candidate != '':
            if returncode == 0:
                return '{} ({})'.format(candidate, tool_path)
            lowered = candidate.lower()
            if 'version' in lowered:
                return '{} ({})'.format(candidate, tool_path)
    return 'FOUND ({}; version unavailable)'.format(tool_path)

def resolve_r_package_versions(packages):
    versions = {pkg: 'UNKNOWN' for pkg in packages}
    rscript_path = shutil.which('Rscript')
    if rscript_path is None:
        return {pkg: 'MISSING (Rscript not found)' for pkg in packages}
    expr = (
        'pkgs <- c({}); '
        'for (pkg in pkgs) {{ '
        'if (requireNamespace(pkg, quietly=TRUE)) {{ '
        'cat(pkg, "\\t", as.character(utils::packageVersion(pkg)), "\\n", sep=""); '
        '}} else {{ '
        'cat(pkg, "\\tMISSING\\n", sep=""); '
        '}} '
        '}}'
    ).format(','.join(['"{}"'.format(pkg) for pkg in packages]))
    returncode, stdout_txt, stderr_txt, exc = run_command_capture([rscript_path, '-e', expr])
    if exc is not None:
        return {pkg: 'UNKNOWN ({})'.format(exc.__class__.__name__) for pkg in packages}
    for line in stdout_txt.splitlines():
        line = line.strip()
        if '\t' not in line:
            continue
        pkg_name, pkg_version = line.split('\t', 1)
        pkg_name = pkg_name.strip()
        pkg_version = pkg_version.strip()
        if pkg_name in versions:
            versions[pkg_name] = pkg_version if pkg_version != '' else 'UNKNOWN'
    if returncode != 0:
        error_line = first_nonempty_line(stderr_txt)
        fallback = 'ERROR (exit code {})'.format(returncode)
        if error_line != '':
            fallback = '{}: {}'.format(fallback, error_line)
        for pkg in packages:
            if versions[pkg] == 'UNKNOWN':
                versions[pkg] = fallback
    return versions

print('AMALGKIT version: {}'.format(__version__))
print('AMALGKIT command: {}'.format(' '.join(sys.argv)))
print('AMALGKIT bug report: https://github.com/kfuku52/amalgkit/issues')
print('AMALGKIT os: {} (os.name={})'.format(describe_os(), os.name))
print('AMALGKIT python: {}'.format(sys.version.split()[0]))
for package_name, module_name in DEPENDENCY_SPECS:
    version = resolve_dependency_version(package_name=package_name, module_name=module_name)
    print('AMALGKIT dependency {}: {}'.format(package_name, version))
for tool_label, tool_exe, version_commands in EXTERNAL_TOOL_SPECS:
    status = resolve_external_tool_status(executable_name=tool_exe, version_commands=version_commands)
    print('AMALGKIT tool {}: {}'.format(tool_label, status))
r_package_versions = resolve_r_package_versions(R_PACKAGE_SPECS)
for r_package in R_PACKAGE_SPECS:
    print('AMALGKIT R package {}: {}'.format(r_package, r_package_versions.get(r_package, 'UNKNOWN')))

def strtobool(val):
    val = val.lower()
    if val in ("y", "yes", "t", "true", "on", "1"):
        return True
    elif val in ("n", "no", "f", "false", "off", "0"):
        return False
    else:
        raise ValueError(f"invalid truth value {val!r}")


def int_or_auto(val):
    if isinstance(val, str) and (val.strip().lower() == 'auto'):
        return 'auto'
    int_val = int(val)
    if int_val <= 0:
        raise ValueError('must be > 0 or "auto"')
    return int_val


def nonnegative_int_or_auto(val):
    if isinstance(val, str) and (val.strip().lower() == 'auto'):
        return 'auto'
    int_val = int(val)
    if int_val < 0:
        raise ValueError('must be >= 0 or "auto"')
    return int_val

def command_metadata(args):
    sys.stdout.write('amalgkit metadata: start\n')
    start = time.time()
    from amalgkit.metadata import metadata_main
    metadata_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit metadata: end\n')

def command_select(args):
    sys.stdout.write('amalgkit select: start\n')
    start = time.time()
    from amalgkit.select import select_main
    select_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit select: end\n')

def command_getfastq(args):
    sys.stdout.write('amalgkit getfastq: start\n')
    start = time.time()
    from amalgkit.getfastq import getfastq_main
    getfastq_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit getfastq: end\n')

def command_quant(args):
    sys.stdout.write('amalgkit quant: start\n')
    start = time.time()
    from amalgkit.quant import quant_main
    try:
        quant_main(args)
    except ValueError as err:
        print("ERROR: ", err)
        sys.exit(1)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit quant: end\n')

def command_cstmm(args):
    sys.stdout.write('amalgkit cstmm: start\n')
    start = time.time()
    from amalgkit.cstmm import cstmm_main
    cstmm_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit cstmm: end\n')

def command_curate(args):
    sys.stdout.write('amalgkit curate: start\n')
    start = time.time()
    from amalgkit.curate import curate_main
    curate_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit curate: end\n')

def command_merge(args):
    sys.stdout.write('amalgkit merge: start\n')
    start = time.time()
    from amalgkit.merge import merge_main
    merge_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit merge: end\n')

def command_busco(args):
    sys.stdout.write('amalgkit busco: start\n')
    start = time.time()
    from amalgkit.busco import busco_main
    busco_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit busco: end\n')

def command_sanity(args):
    sys.stdout.write('amalgkit sanity: start\n')
    start = time.time()
    from amalgkit.sanity import sanity_main
    sanity_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit sanity: end\n')

def command_integrate(args):
    sys.stdout.write('amalgkit integrate: start\n')
    start = time.time()
    from amalgkit.integrate import integrate_main
    integrate_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit integrate: end\n')

def command_csca(args):
    sys.stdout.write('amalgkit csca: start\n')
    start = time.time()
    from amalgkit.csca import csca_main
    csca_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit csca: end\n')

def command_config(args):
    sys.stdout.write('amalgkit config: start\n')
    start = time.time()
    from amalgkit.config import config_main
    config_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit config: end\n')

def command_dataset(args):
    sys.stdout.write('amalgkit dataset: start\n')
    start = time.time()
    from amalgkit.dataset import dataset_main
    dataset_main(args)
    print('Time elapsed: {:,} sec'.format(int(time.time() - start)))
    sys.stdout.write('amalgkit dataset: end\n')

def command_help(args):
    topic = getattr(args, 'topic', None)
    if topic is None:
        parser.print_help()
        return
    parser.parse_args([topic, '--help'])


# Main parser
parser = argparse.ArgumentParser(description='A toolkit for cross-species transcriptome amalgamation')
parser.add_argument('--version', action='version', version='amalgkit version ' + __version__)
subparsers = parser.add_subparsers()

# Parent parsers
pp_meta = argparse.ArgumentParser(add_help=False)
pp_meta.add_argument('--metadata', metavar='PATH', default='inferred', type=str, required=False, action='store',
                 help='default=%(default)s: "inferred" = out_dir/metadata/metadata.tsv. '
                      'PATH to metadata table, the output file of `amalgkit metadata`.')
pp_out = argparse.ArgumentParser(add_help=False)
pp_out.add_argument('--out_dir', metavar='PATH', default='./', type=str, required=False, action='store',
                 help='default=%(default)s: PATH to the directory where intermediate and output files are generated.')
pp_batch = argparse.ArgumentParser(add_help=False)
pp_batch.add_argument('--batch', metavar='INT', default=None, type=int, required=False, action='store',
                 help='default=%(default)s: One-based index of metadata table (--metadata). '
                      'If set, process only one SRA record. This function is intended for array job processing. '
                      'If multiple batch jobs run at the same time, total CPU demand scales with the number of concurrent batch jobs.')
pp_redo = argparse.ArgumentParser(add_help=False)
pp_redo.add_argument('--redo', metavar='yes|no', default='no', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Redo the analysis even if previous output files are detected.')
pp_threads = argparse.ArgumentParser(add_help=False)
pp_threads.add_argument('--threads', metavar='INT|auto', default='auto', type=int_or_auto, required=False, action='store',
                 help='default=%(default)s: Total CPU cores to use per amalgkit process. '
                      'This is a global core budget (not per-worker threads). '
                      'AMALGKIT auto-splits this budget into internal workers and per-worker threads.')
pp_internal_jobs = argparse.ArgumentParser(add_help=False)
pp_internal_jobs.add_argument('--internal_jobs', metavar='INT|auto', default='auto', type=int_or_auto, required=False, action='store',
                 help='default=%(default)s: Advanced override for internal parallel workers. '
                      'In auto mode, worker count is derived from --threads. '
                      'When --batch is set, this is forced to 1.')
pp_cpu_budget = argparse.ArgumentParser(add_help=False)
pp_cpu_budget.add_argument('--internal_cpu_budget', metavar='INT|auto', default='auto', type=nonnegative_int_or_auto, required=False, action='store',
                 help='default=%(default)s: Advanced CPU budget cap for internal auto-parallelization. '
                      'The effective core budget is min(--threads, --internal_cpu_budget). '
                      '"auto" uses os.cpu_count().')
pp_sg = argparse.ArgumentParser(add_help=False)
pp_sg.add_argument('--sample_group', metavar='tissueA,tissueB,tissueC,...', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: "Comma separated list of sample groups. '
                      'By default, all sample_group values in metadata.tsv are passed.')
pp_sgc = argparse.ArgumentParser(add_help=False)
pp_sgc.add_argument('--sample_group_color', metavar='#d95f02ff,#1b9e77ff,#7570b3ff,...', default='DEFAULT', type=str, required=False, action='store',
                 help='default=%(default)s: "Comma separated list of sample groups colors. '
                      'The order should be the same as --sample_group. '
                      'The number of colors should be the same as the number of selected sample groups. '
                      'By default, all colors are automatically assigned.')

# Sub parser: metadata
pme_help = 'NCBI SRA metadata retrieval and curation. See `amalgkit metadata -h`'
pme = subparsers.add_parser('metadata', help=pme_help, parents=[pp_out, pp_redo])
pme.add_argument('--search_string', metavar='PATH', default=None, type=str, required=True, action='store',
                 help='default=%(default)s: Entrez search string. See https://www.ncbi.nlm.nih.gov/books/NBK25499/ for details. '
                      'The search string is used to identify SRA entries that can be found at https://www.ncbi.nlm.nih.gov/sra/ using the same string. '
                      'Example: "Cephalotus follicularis"[Organism] AND "Illumina"[Platform] AND "RNA-seq"[Strategy]')
pme.add_argument('--entrez_email', metavar='aaa@bbb.com', default='', type=str, required=False, action='store',
                 help='default=%(default)s: Your email address. See https://www.ncbi.nlm.nih.gov/books/NBK25497/')
pme.add_argument('--resolve_names', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Whether to resolve scientific names based on NCBI Taxonomy IDs.')
pme.set_defaults(handler=command_metadata)

# Sub parser: select
pse_help = 'Selecting SRA entries for analysis. See `amalgkit select -h`'
pse = subparsers.add_parser('select', help=pse_help, parents=[pp_out, pp_meta, pp_sg])
pse.add_argument('--config_dir', metavar='PATH', default='inferred', type=str, required=False, action='store',
                 help='default=%(default)s: PATH to the config directory. "inferred" = out_dir/config')
pse.add_argument('--min_nspots', metavar='INT', default=5000000, type=int, required=False, action='store',
                 help='default=%(default)s: Minimum number of RNA-seq reads per sample.')
pse.add_argument('--max_sample', metavar='INT', default=99999, type=int, required=False, action='store',
                 help='default=%(default)s: Maximum number of RNA-seq data to retain for one sample group in a species.')
pse.add_argument('--mark_missing_rank', metavar='species|genus|family|order|class|phylum|kingdom|domain|none', default='species', type=str, required=False, action='store',
                 choices=['species', 'genus', 'family', 'order', 'class', 'phylum', 'kingdom', 'domain', 'none'],
                 help='default=%(default)s: Mark samples lacking taxid information at the specified rank as unqualified.')
pse.add_argument('--mark_redundant_biosamples', metavar='no|yes', default='no', type=strtobool,
                 required=False, action='store',
                 help='default=%(default)s: Whether to label SRAs with the same BioSample ID as unqualified.')
pse.set_defaults(handler=command_select)

# Sub parser: getfastq
pge_help = 'Retrieving fastq files. See `amalgkit getfastq -h`'
pge = subparsers.add_parser('getfastq', help=pge_help, parents=[pp_out, pp_meta, pp_threads, pp_internal_jobs, pp_cpu_budget, pp_redo, pp_batch])
pge.add_argument('--entrez_email', metavar='aaa@bbb.com', default='', type=str, required=False, action='store',
                 help='default=%(default)s: Your email address. See https://www.ncbi.nlm.nih.gov/books/NBK25497/')
pge.add_argument('--id', metavar='XXXXX0000', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: BioProject/BioSample/SRR ID. This option can be used to directly specify '
                      'an ID to start FASTQ generation without running `amalgkit metadata` beforehand.')
pge.add_argument('--id_list', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: Location of file containing a list of SRA IDs. Otherwise works like --id')
pge.add_argument('--layout', metavar='single|paired|auto', default='auto', type=str, required=False, action='store',
                 choices=['single', 'paired', 'auto'],
                 help='default=%(default)s: Library layout of RNA-seq data to be dumped. '
                      '"auto" prioritizes paird-end libraries if both types are available.')
pge.add_argument('--max_bp', metavar='INT', default='999,999,999,999,999', type=str, required=False, action='store',
                 help='default=%(default)s: Target sequence size (bp) to be dumped.')
pge.add_argument('--min_read_length', metavar='INT', default=25, type=int, required=False, action='store',
                 help='default=%(default)s: Minimum read length.')
pge.add_argument('--pfd', dest='obsolete_pfd', metavar='yes|no', default=None, type=strtobool,
                 required=False, action='store', help=argparse.SUPPRESS)
pge.add_argument('--pfd_exe', dest='obsolete_pfd_exe', metavar='PATH', default=None, type=str,
                 required=False, action='store', help=argparse.SUPPRESS)
pge.add_argument('--fastq_dump_exe', dest='obsolete_fastq_dump_exe', metavar='PATH', default=None, type=str,
                 required=False, action='store', help=argparse.SUPPRESS)
pge.add_argument('--fasterq_dump_exe', '--fasterq-dump_exe', '--fasterq-dump-exe',
                 dest='fasterq_dump_exe', metavar='PATH', default='fasterq-dump', type=str,
                 required=False, action='store',
                 help='default=%(default)s: PATH to fasterq-dump executable for public SRA extraction.')
pge.add_argument('--seqkit_exe', metavar='PATH', default='seqkit', type=str, required=False, action='store',
                 help='default=%(default)s: PATH to seqkit executable used for FASTQ .gz output.')
pge.add_argument('--fasterq_size_check', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Toggle fasterq-dump pre-run disk-size checks. '
                      '"yes" forwards --size-check on, "no" forwards --size-check off.')
pge.add_argument('--fasterq_disk_limit', metavar='STR', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: Optional value forwarded to fasterq-dump --disk-limit '
                      '(for example, "200G").')
pge.add_argument('--fasterq_disk_limit_tmp', metavar='STR', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: Optional value forwarded to fasterq-dump --disk-limit-tmp '
                      '(for example, "200G").')
pge.add_argument('--prefetch_exe', dest='obsolete_prefetch_exe', metavar='PATH', default=None, type=str,
                 required=False, action='store', help=argparse.SUPPRESS)
pge.add_argument('--fastp', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Run fastp.')
pge.add_argument('--fastp_exe', metavar='PATH', default='fastp', type=str, required=False, action='store',
                 help='default=%(default)s: PATH to fastp executable.')
pge.add_argument('--fastp_option', metavar='STR', default='-j /dev/null -h /dev/null', type=str, required=False,
                 action='store',
                 help='default=%(default)s: Options to be passed to fastp. Do not include --length_required option here. '
                      'It can be specified throught --min_read_length in amalgkit. ')
pge.add_argument('--remove_sra', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Remove downloaded SRA files after fastq extraction.')
pge.add_argument('--remove_tmp', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Remove temporary files.')
pge.add_argument('--dump_print', '--pfd_print', dest='dump_print', metavar='yes|no', default='yes', type=strtobool,
                 required=False, action='store',
                 help='default=%(default)s: Show sequence extraction (fasterq-dump/compression) stdout and stderr. '
                      '--pfd_print is supported as an obsolete alias.')
pge.add_argument('--fastp_print', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Show fastp stdout and stderr.')
pge.add_argument('--sci_name', metavar='STR', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: Species name in case the BioProject covers multiple species. Example: "Homo sapiens"')
pge.add_argument('--ncbi', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Download SRA files using wget from NCBI cloud, if available.')
pge.add_argument('--aws', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Download SRA files from Amazon Cloud (AWS), if available.')
pge.add_argument('--gcp', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Download SRA files from Google Cloud (GCP), if available.')
pge.add_argument('--gcp_project', metavar='STR', default='', type=str, required=False, action='store',
                 help='default=%(default)s: Google Cloud project for requester-pays GCP buckets (used when GCP_Link is gs://).')
pge.add_argument('--read_name', metavar='default|trinity', default='default', type=str, required=False, action='store',
                 choices=['default', 'trinity'],
                 help='default=%(default)s: read name formatting for downstream analysis.')
pge.add_argument('--entrez_additional_search_term', metavar='STR',
                 default=None,
                # default='"platform illumina"[Properties] AND "type rnaseq"[Filter] AND "sra biosample"[Filter]',
                 type=str, required=False, action='store',
                 help='default=%(default)s: Entrez search terms in addition to --id option to further restrict the SRA entry.')
pge.add_argument('--tol', metavar='FLOAT', default=1, type=float, required=False, action='store',
                 help='default=%(default)s: Acceptable percentage loss of reads relative to --max_bp. If the 1st-round sequence '
                      'generation could not produce enough reads, the 2nd-round sequence generation is activated to '
                      'compensate the loss.')
pge.set_defaults(handler=command_getfastq)

# Sub parser: quant
pqu_help = 'Estimating transcript abundance with kallisto. See `amalgkit quant -h`'
pqu = subparsers.add_parser('quant', help=pqu_help, parents=[pp_out, pp_meta, pp_threads, pp_internal_jobs, pp_cpu_budget, pp_redo, pp_batch])

pqu.add_argument('--index_dir', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to index directory. Only required if index directory is not '
                      'out_dir/index/')
pqu.add_argument('--clean_fastq', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Remove getfastq-processed fastq files when quant is successfully completed.')
pqu.add_argument('--fasta_dir', metavar='PATH', default='inferred', type=str, required=False, action='store',
                 help='default=%(default)s: "inferred" = out_dir/fasta. '
                      'PATH to directory containing reference transcriptome fasta files required for kallisto index building (see --build_index). '
                      'In this directory, file names of fasta files are expected to start with the string '
                      'in the "scientific_name" column of the metadata table, with a space replaced with an underbar. '
                      'Example: Arabidopsis_thaliana_v1.fasta for Arabidopsis thaliana.')
pqu.add_argument('--build_index', metavar='yes|no', default='no', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Allows AMALGKIT to build kallisto index from reference fasta files. '
                      'Will only do this for a species if an index file is not already present. One fasta file per species should be put in --fasta_dir. '
                      'AMALGKIT will read the species from the metadata, try to find the fasta file (.fa or .fasta) and build the index for further use.')
pqu.add_argument('--index_lock_poll', metavar='INT', default=5, type=int, required=False, action='store',
                 help='default=%(default)s: Poll interval in seconds while waiting for another batch process to finish building a species index.')
pqu.add_argument('--index_lock_timeout', metavar='INT', default=3600, type=int, required=False, action='store',
                 help='default=%(default)s: Maximum wait time in seconds for index build lock release before aborting.')
pqu.set_defaults(handler=command_quant)

# Sub parser: merge
pmg_help = 'Generating transcript abundance tables. See `amalgkit merge -h`'
pmg = subparsers.add_parser('merge', help=pmg_help, parents=[pp_out, pp_meta, pp_threads, pp_internal_jobs, pp_cpu_budget])
pmg.set_defaults(handler=command_merge)

# Sub parser: busco
pbu_help = 'Generating BUSCO tables for amalgkit cstmm/csca. See `amalgkit busco -h`'
pbu = subparsers.add_parser('busco', help=pbu_help, parents=[pp_out, pp_meta, pp_threads, pp_internal_jobs, pp_cpu_budget, pp_redo])
pbu.add_argument('--tool', metavar='auto|busco|compleasm', default='auto', type=str, required=False, action='store',
                 choices=['auto', 'busco', 'compleasm'],
                 help='default=%(default)s: Tool for BUSCO table generation.')
pbu.add_argument('--lineage', metavar='STR', default=None, type=str, required=True, action='store',
                 help='Lineage dataset name (e.g., eukaryota_odb12).')
pbu.add_argument('--fasta_dir', metavar='PATH', default='inferred', type=str, required=False, action='store',
                 help='default=%(default)s: "inferred" = out_dir/fasta. Directory with transcriptome fasta files.')
pbu.add_argument('--fasta', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='Optional: single fasta path to process (requires --species).')
pbu.add_argument('--species', metavar='STR', default=None, type=str, required=False, action='store',
                 help='Optional: species name used with --fasta (e.g., "Homo sapiens").')
pbu.add_argument('--busco_exe', metavar='PATH', default='busco', type=str, required=False, action='store',
                 help='default=%(default)s: PATH to busco executable.')
pbu.add_argument('--compleasm_exe', metavar='PATH', default='compleasm', type=str, required=False, action='store',
                 help='default=%(default)s: PATH to compleasm executable.')
pbu.add_argument('--tool_args', metavar='STR', default=None, type=str, required=False, action='store',
                 help='Additional arguments passed to the selected tool.')
pbu.set_defaults(handler=command_busco)

# Sub parser: cstmm
pcs_help = 'Applying cross-species TMM normalization using single-copy genes. See `amalgkit cstmm -h`'
pcs = subparsers.add_parser('cstmm', help=pcs_help, parents=[pp_out, pp_meta])
pcs.add_argument('--orthogroup_table', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to orthogroup table, which is, for example, Orthogroups.tsv and N0.tsv in OrthoFinder.'
                      'Specify `--orthogroup_table ""` for single-species TMM normalization.')
pcs.add_argument('--dir_busco', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to the directory where per-species BUSCO full tables are stored. '
                      'File names in this directory are expected to be GENUS_SPECIES_busco.tsv: e.g., Arabidopsis_thaliana_busco.tsv')
pcs.add_argument('--dir_count', metavar='PATH', default='inferred', type=str, required=False, action='store',
                 help='default=%(default)s: AMALGKIT subfolder PATH to per-species transcript abundance data as produced by `amalgkit merge`. '
                      '"inferred" = out_dir/merge')
pcs.set_defaults(handler=command_cstmm)

# Sub parser: csca
pca_help = 'Generating plots with cross-species correlation analysis. See `amalgkit csca -h`'
pca = subparsers.add_parser('csca', help=pca_help, parents=[pp_out, pp_meta, pp_sg, pp_sgc])
pca.add_argument('--orthogroup_table', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to orthogroup table, which is, for example, Orthogroups.tsv and N0.tsv in OrthoFinder.')
pca.add_argument('--dir_busco', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to the directory where per-species BUSCO full tables are stored. '
                      'File names in this directory are expected to be GENUS_SPECIES_busco.tsv: e.g., Arabidopsis_thaliana_busco.tsv')
pca.add_argument('--batch_effect_alg', metavar='(no|sva|ruvseq|combatseq)', choices=['no', 'sva', 'ruvseq', 'combatseq'],
                 default='sva', type=str, required=False, action='store',
                 help='default=%(default)s: Batch-effect removal algorithm used in `amalgkit curate`.')
pca.add_argument('--missing_strategy', metavar='em_pca|nipals|row_mean',
                 choices=['em_pca', 'nipals', 'row_mean'],
                 default='em_pca', type=str, required=False, action='store',
                 help='default=%(default)s: Missing-value handling strategy before csca dimensionality reduction. '
                      '`em_pca` uses a dependency-free iterative low-rank reconstruction (EM/PPCA-style). '
                      '`nipals` uses a dependency-free NIPALS-style low-rank iterative reconstruction. '
                      '`row_mean` uses per-gene mean fill as a fast fallback.')
pca.set_defaults(handler=command_csca)

# Sub parser: curate
pcu_help = 'Automatic removal of outlier samples and SVA-based unwanted biases. See `amalgkit curate -h`'
pcu = subparsers.add_parser('curate', help=pcu_help, parents=[pp_out, pp_meta, pp_batch, pp_threads, pp_internal_jobs, pp_cpu_budget, pp_sg, pp_sgc, pp_redo])
pcu.add_argument('--input_dir', metavar='PATH', default='inferred', type=str, required=False, action='store',
                 help='default=%(default)s: PATH to `amalgkit merge` or `amalgkit cstmm` output folder. '
                      '"inferred" = out_dir/cstmm if exist, else out_dir/merge.')
pcu.add_argument('--dist_method', metavar='STR', default='pearson', type=str, required=False, action='store',
                 help='default=%(default)s: Method for calculating distance.')
pcu.add_argument('--mapping_rate', metavar='FLOAT', default=0.20, type=float, required=False, action='store',
                 help='default=%(default)s: Cutoff for mapping rate.')
pcu.add_argument('--correlation_threshold', metavar='FLOAT', default=0.30, type=float, required=False, action='store',
                 help='default=%(default)s: Lower cutoff for pearson r during outlier removal.')
pcu.add_argument('--plot_intermediate', metavar='yes|no', default='no', type=strtobool, required=False, action='store',
                 help='default=%(default)s: If yes, calculates and plots SVA correction after each iteration of outlier removal. Drastically increases computing times!')
pcu.add_argument('--one_outlier_per_iter', metavar='yes|no', default='no', type=strtobool, required=False, action='store',
                 help='default=%(default)s: If yes, allows curate to remove only 1 sample per same-sample-group or same-bioproject. Increases computing times!')
pcu.add_argument('--norm', metavar='(logn|log2|lognp1|log2p1|none)-(fpkm|tpm|none)',
                 default='log2p1-fpkm', type=str, required=False, action='store',
                 help='default=%(default)s: Expression level transformation before the batch effect removal. '
                      'SVA is best performed with log-transformed values. '
                      'logn: log_n normalization after FPKM/TPM transformation. '
                      'log2: log_2 normalization after FPKM/TPM transformation. '
                      'lognp1: log_n(x+1) normalization after FPKM/TPM transformation. '
                      'log2p1: log_2(x+1) normalization after FPKM/TPM transformation. '
                      'fpkm/tpm/none: FPKM, TPM, or no transformation. ')
pcu.add_argument('--batch_effect_alg', metavar='(no|sva|ruvseq|combatseq)', choices=['no', 'sva', 'ruvseq', 'combatseq'],
                 default='sva', type=str, required=False, action='store',
                 help='default=%(default)s: Batch-effect removal algorithm. '
                 'no: No batch-effect removal. '
                 'sva: Surrogate variable analysis. Use with log-transformed values. '
                 'ruvseq: Experimental. Batch effect removal based on control genes. Control genes are obtained from the residuals of a GLM. '
                 'combatseq: Experimental. Batch effect removal based on BioProject IDs. '
                 'If log-fpkm/tpm is set in combination with ruvseq or combatseq, transformation will be applied after batch-effect removal. ')
pcu.add_argument('--clip_negative', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Negative values will be clipped to 0 after the batch effect removal, '
                      'if the log*p1-* transformation is applied before the batch effect removal.')
pcu.add_argument('--maintain_zero', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Any instances of zero expression levels in the input will remain as '
                      'zero-values in the output tables, even if the process of batch effect removal causes deviation.')
pcu.add_argument('--skip_curation', metavar='yes|no', default='no', type=strtobool, required=False, action='store',
                 help='default=%(default)s: stops curate before mapping-rate based sample removal step. Outputs only '
                      'uncorrected + transformed (see --norm) count-table and the corresponding mean count-table.')
pcu.set_defaults(handler=command_curate)

# Sub parser: sanity
psa_help = 'Checking the integrity of AMALGKIT input and output files. See `amalgkit sanity -h`'
psa = subparsers.add_parser('sanity', help=psa_help, parents=[pp_out, pp_meta])
psa.add_argument('--index', required=False, action='store_true',
                 help='set this option if you want to check for availability of index files '
                      'based on species name in metadata file.')
psa.add_argument('--quant', required=False, action='store_true',
                 help='set this option if you want to check for availability quant output files '
                      'based on SRA IDs in metadata file.')
psa.add_argument('--getfastq', required=False, action='store_true',
                 help='set this option if you want to check for availability of getfastq output files '
                      'based on SRA IDs in metadata file.')
psa.add_argument('--all', required=False, action='store_true',
                 help='setting this option runs amalgkit sanity as if --index, --quant, --getfastq were set')
psa.add_argument('--index_dir', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to index directory. Only required if index directory is not '
                      'out_dir/index/')
psa.add_argument('--quant_dir', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to quant directory. Only required if quant directory is not '
                      'out_dir/quant/')
psa.add_argument('--getfastq_dir', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to index directory. Only required if getfastq directory is not '
                      'out_dir/getfastq/')
psa.add_argument('--quiet', metavar='yes|no', default='no', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Suppress per-run status lines and print only summary results.')
psa.add_argument('--verbose_runs', metavar='INT', default=20, type=int, required=False, action='store',
                 help='default=%(default)s: Maximum number of runs for per-run logging in sanity checks. '
                      'Set a negative value to always print per-run logs.')
psa.set_defaults(handler=command_sanity)

# Sub parser: integrate
pin_help = 'Appending local fastq info to a metadata table. See `amalgkit integrate -h`'
pin = subparsers.add_parser('integrate', help=pin_help, parents=[pp_out, pp_meta, pp_threads])
pin.add_argument('--fastq_dir', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to input directory where fastq files are stored.')
pin.add_argument('--getfastq_dir', metavar='PATH', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: PATH to index directory. Only required if getfastq directory is not '
                      'out_dir/getfastq/')
pin.add_argument('--remove_tmp', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Remove temporary files.')
pin.add_argument('--accurate_size', metavar='yes|no', default='yes', type=strtobool, required=False, action='store',
                 help='default=%(default)s: ONLY APPLIES TO .gz COMPRESSED FASTQ FILES. If no, scans the first 1,000 reads '
                      'to estimate average read length. If yes, scans the whole file for exact statistics.')
pin.set_defaults(handler=command_integrate)

# Sub parser: config
pco_help = 'Creating a series of config files for the metadata search. See `amalgkit config -h`'
pco = subparsers.add_parser('config', help=pco_help, parents=[pp_out])
pco.add_argument('--config', metavar='base|test|plantae|vertebrate', default='base', type=str, required=False, action='store',
                 help='default=%(default)s: Name of config dataset to be exported. Options: '
                      '"base": a minimal set of .config files for the purpose of creating custom config files. '
                      '"base_all": a complete set of near-empty .config files. '
                      '"test": short animal set for testing amalgkit metadtata. '
                      '"vertebrate" preconfigured set of config files for vertebrate animal data.'
                      '"plantae": preconfigured set of config files for plant data.')
pco.add_argument('--overwrite', metavar='yes|no', default='no', type=strtobool, required=False, action='store',
                 help='default=%(default)s: allow to overwrite config files in out_dir/config/config_name/ .')
pco.set_defaults(handler=command_config)

# Sub parser: dataset
pda_help = 'Extracting bundled test datasets. See `amalgkit dataset -h`'
pda = subparsers.add_parser('dataset', help=pda_help, parents=[pp_out])
pda.add_argument('--name', metavar='yeast|...', default=None, type=str, required=False, action='store',
                 help='default=%(default)s: Name of the dataset to extract. Use --list to see available datasets.')
pda.add_argument('--list', default=False, required=False, action='store_true',
                 help='List available datasets and exit.')
pda.add_argument('--overwrite', metavar='yes|no', default='no', type=strtobool, required=False, action='store',
                 help='default=%(default)s: Allow overwriting existing files.')
pda.set_defaults(handler=command_dataset)

# Sub parser: help
parser_help = subparsers.add_parser('help', help='Printing help messages')
parser_help.add_argument(
    'topic',
    nargs='?',
    default=None,
    choices=['metadata', 'select', 'getfastq', 'quant', 'merge', 'busco', 'cstmm', 'csca', 'curate', 'sanity', 'integrate', 'config', 'dataset', 'help'],
    help='Optional command name to show detailed help for.',
)
parser_help.set_defaults(handler=command_help)

# Handler
args = parser.parse_args()
if hasattr(args, 'handler'):
    args.handler(args)
else:
    parser.print_help()
